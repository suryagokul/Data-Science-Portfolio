{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_based_collaborative_filtering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMf7r2ycYpnYzD30M2szWwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryagokul/Data-Science-Portfolio/blob/master/model_based_collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRbNXr3L3k4"
      },
      "source": [
        "#  Model-based collaborative filtering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4amzxC539k88"
      },
      "source": [
        "Model-based collaborative filtering methods first create a model of the user, and then build the predictions.\n",
        "\n",
        "### Types of models\n",
        "- Probabilistic\n",
        "- Classification\n",
        "- Regression\n",
        "- Clustering\n",
        "- Rule-based\n",
        "\n",
        "\n",
        "The netflix prize was a model-baed collaborative filtering.\n",
        "\n",
        "Top 2 algorithms in the Netflix prize:\n",
        "- SVD (matrix factorization) -- RMSE 0.8914\n",
        "- RBM (Restricted Boltzman Machines - neural network) -- RMSE 0.8990\n",
        "- Ensemble of the two -- RMSE 0.88"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmyTNkPNT4Uw"
      },
      "source": [
        "# Using SVD (SINGULAR VALUE DECOMPOSITION):\n",
        "\n",
        "\n",
        "### Intution behind SVD:\n",
        "\n",
        "The basic idea is that the matrix I start off with, the $X$ matrix, which is very sparse and had the users and the items, I want to colapse it into something that has less dimensions and is much less sparse.\n",
        "\n",
        "We're going to do that by decomposing my original matrix X into 3:\n",
        "* $U$ == left singular matrix, representing the relationship between users and latent factors\n",
        "* $S$ == diagonal matrix describing the strength of each latent factor\n",
        "* $V$ == right singular matrix, indicating the similarity between items and latent factors. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "r is the number of factors that are in my decompositions.\n",
        "\n",
        "\n",
        "\n",
        "### **Latent factors?**\n",
        "Latent factors describe a property or concept that a user or an item have. \n",
        "For instance, for music, latent factor can refer to the genre that the music belongs to. SVD decreases the dimension of the utility matrix by extracting its latent factors. Essentially, we map each user and each item into a latent space with dimension r. Therefore, it helps us better understand the relationship between users and items as they become directly comparable.\n",
        "\n",
        "**Video References of SVD Working**\n",
        "\n",
        "1. [Fantastic Explanation of Netflix Prize Using SVD.](https://www.youtube.com/watch?v=sooj-_bXWgk&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv&index=9)\n",
        "\n",
        "2. [Explanation on Matrix Factorization used by SVD.](https://www.youtube.com/watch?v=ZspR5PZemcs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zpoz98F81UV"
      },
      "source": [
        "## Hands-on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IMXMBgI9GB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e929954-9c70-4a8f-8e9e-0f8dc57b3c60"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1670913 sha256=c2d82bbaef477784fc2f5802c030ff361a940885d42854dacc0f33a5ed98d51a\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3-_67QY9OoU"
      },
      "source": [
        "**Note:** After installing, please restart the runtime (Runtime --> Restart runtime)\n",
        "\n",
        "\n",
        "### 2. Import packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLHChfxa9eWA"
      },
      "source": [
        "from surprise import Dataset, SVD\n",
        "from surprise.model_selection import cross_validate, split\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHKSiVyO-wvq"
      },
      "source": [
        "### 3. Getting data\n",
        "\n",
        "\n",
        "The `surprise` package has support for downloading movielens dataset, and we're going to use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvVqGHn5-5MQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6602172-5e78-4459-af80-0dd79def8d3e"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] \n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3ozFWucHhXc"
      },
      "source": [
        "### 4. Plug-in SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX40Q_oh_UNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cdafd2-f61a-4d70-f352-474150bef180"
      },
      "source": [
        "# Use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9291  0.9439  0.9372  0.9327  0.9363  0.9358  0.0050  \n",
            "MAE (testset)     0.7333  0.7435  0.7380  0.7362  0.7397  0.7381  0.0034  \n",
            "Fit time          4.74    4.76    4.73    4.75    4.74    4.74    0.01    \n",
            "Test time         0.20    0.13    0.20    0.13    0.20    0.17    0.03    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (4.738926649093628,\n",
              "  4.763303518295288,\n",
              "  4.72601056098938,\n",
              "  4.749563455581665,\n",
              "  4.743380784988403),\n",
              " 'test_mae': array([0.73329184, 0.74350207, 0.73796941, 0.73618822, 0.73971734]),\n",
              " 'test_rmse': array([0.92905726, 0.94389489, 0.9371952 , 0.93271503, 0.93630608]),\n",
              " 'test_time': (0.20218849182128906,\n",
              "  0.13275957107543945,\n",
              "  0.1959681510925293,\n",
              "  0.1342453956604004,\n",
              "  0.19782733917236328)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhR7pdTWFmy"
      },
      "source": [
        "## Surprise Library Documentations\n",
        "\n",
        "Surprise already has implemented multiple models, they can be found here: http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html\n",
        "\n",
        "Also a benchmark of them can be found: http://surpriselib.com\n"
      ]
    }
  ]
}